{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lukemoberly/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LondonEmotions.utils import create_embedding_matrix\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    clean and preprocess data\n",
    "    \"\"\"\n",
    "    # Process reviews that are numbers\n",
    "    data['Text'] = data['Text'].astype(str)\n",
    "    \n",
    "    # Remove numbers\n",
    "    data['clean_text'] = data['Text'].apply(\n",
    "        lambda x: ''.join([let for let in x if not let.isdigit()])\n",
    "        )\n",
    "    # Lowercase text\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: x.lower()\n",
    "        )\n",
    "    # Strip whitespace\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: x.strip()\n",
    "        )\n",
    "    # Remove punctuation\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: ''.join(let for let in x if not let in string.punctuation)\n",
    "        )\n",
    "    # Tokenization with nltk\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: word_tokenize(x)\n",
    "    )\n",
    "    # Remove stopwords\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # data['clean_text'] = data['clean_text'].apply(\n",
    "    #     lambda x: [word for word in x if word not in stop_words]\n",
    "    #     )\n",
    "    # Lemmatizing with nltk\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x)\n",
    "        )\n",
    "\n",
    "    # Tokenizing text\n",
    "    data['tokenized_text'] = [utils.simple_preprocess(line, deacc=True) for line in data['clean_text']]\n",
    "    # Return data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Nice budget hotel....room is clean and well ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>This hotel is well managed with great staff on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>10 our of 10 lovely service, clean and homely....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Very Dirty, carpet never been cleaned, Curry s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Even 1 star is too much for this terrible hote...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id        lat       lng  \\\n",
       "0  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "1  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "2  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "3  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "4  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "\n",
       "                                                Text  \n",
       "0  Nice budget hotel....room is clean and well ma...  \n",
       "1  This hotel is well managed with great staff on...  \n",
       "2  10 our of 10 lovely service, clean and homely....  \n",
       "3  Very Dirty, carpet never been cleaned, Curry s...  \n",
       "4  Even 1 star is too much for this terrible hote...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv('../raw_data/prediction.csv')\n",
    "review_df.rename(columns = {'review': 'Text'}, inplace=True)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Nice budget hotel....room is clean and well ma...</td>\n",
       "      <td>nice budget hotelroom is clean and well mainta...</td>\n",
       "      <td>[nice, budget, hotelroom, is, clean, and, well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>This hotel is well managed with great staff on...</td>\n",
       "      <td>this hotel is well managed with great staff on...</td>\n",
       "      <td>[this, hotel, is, well, managed, with, great, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>10 our of 10 lovely service, clean and homely....</td>\n",
       "      <td>our of lovely service clean and homely with lo...</td>\n",
       "      <td>[our, of, lovely, service, clean, and, homely,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Very Dirty, carpet never been cleaned, Curry s...</td>\n",
       "      <td>very dirty carpet never been cleaned curry sta...</td>\n",
       "      <td>[very, dirty, carpet, never, been, cleaned, cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Even 1 star is too much for this terrible hote...</td>\n",
       "      <td>even star is too much for this terrible hotel ...</td>\n",
       "      <td>[even, star, is, too, much, for, this, terribl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id        lat       lng  \\\n",
       "0  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "1  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "2  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "3  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "4  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Nice budget hotel....room is clean and well ma...   \n",
       "1  This hotel is well managed with great staff on...   \n",
       "2  10 our of 10 lovely service, clean and homely....   \n",
       "3  Very Dirty, carpet never been cleaned, Curry s...   \n",
       "4  Even 1 star is too much for this terrible hote...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  nice budget hotelroom is clean and well mainta...   \n",
       "1  this hotel is well managed with great staff on...   \n",
       "2  our of lovely service clean and homely with lo...   \n",
       "3  very dirty carpet never been cleaned curry sta...   \n",
       "4  even star is too much for this terrible hotel ...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [nice, budget, hotelroom, is, clean, and, well...  \n",
       "1  [this, hotel, is, well, managed, with, great, ...  \n",
       "2  [our, of, lovely, service, clean, and, homely,...  \n",
       "3  [very, dirty, carpet, never, been, cleaned, cu...  \n",
       "4  [even, star, is, too, much, for, this, terribl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = clean_data(review_df)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "embed_num_dims = 300\n",
    "max_seq_len = 300\n",
    "class_names = ['joy', 'worry', 'anger', 'sad', 'neutral']\n",
    "\n",
    "reviews = review_df['tokenized_text']\n",
    "\n",
    "sentences_pred = [[_ for _ in sentence] for sentence in reviews]\n",
    "\n",
    "texts_pred = [' '.join([x for x in sentence]) for sentence in sentences_pred]\n",
    "\n",
    "# Tokenize text (convert to integers)\n",
    "filepath = '../raw_data/tokenizer.pickle'\n",
    "with file_io.FileIO(filepath, mode='rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "sequence_pred = tokenizer.texts_to_sequences(texts_pred)\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "# vacab size is number of unique words + reserved 0 index for padding\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "# Padding text sentences\n",
    "X_pred_pad = pad_sequences(sequence_pred, maxlen = max_seq_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  197,   84,  537],\n",
       "       [   0,    0,    0, ..., 3334,  541,  876],\n",
       "       [   0,    0,    0, ...,  876,   19,   23],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 8558,  271,  684],\n",
       "       [   0,    0,    0, ..., 5649,   73, 1052],\n",
       "       [   0,    0,    0, ...,  749,  294,  211]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44733, 300)\n"
     ]
    }
   ],
   "source": [
    "# Encode target\n",
    "encoding = {\n",
    "'anger': 0,\n",
    "'joy': 1,\n",
    "'worry': 2,\n",
    "'neutral': 3,\n",
    "'sad': 4\n",
    "}\n",
    "\n",
    "# Create embedding matrix\n",
    "file_path = '../embeddings/wiki-news-300d-1M.vec'\n",
    "\n",
    "embedd_matrix = create_embedding_matrix(file_path, index_of_words, embed_num_dims)\n",
    "print(embedd_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('../raw_data/saved_model_2.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  197,   84,  537],\n",
       "       [   0,    0,    0, ..., 3334,  541,  876],\n",
       "       [   0,    0,    0, ...,  876,   19,   23],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 8558,  271,  684],\n",
       "       [   0,    0,    0, ..., 5649,   73, 1052],\n",
       "       [   0,    0,    0, ...,  749,  294,  211]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_pred_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02905648 0.19406627 0.50860006 0.0276215  0.24065568]\n",
      " [0.12818776 0.07312929 0.45927614 0.07705467 0.2623521 ]\n",
      " [0.05074719 0.5071262  0.15375517 0.19909781 0.08927361]\n",
      " ...\n",
      " [0.08875266 0.20280546 0.5838012  0.05758075 0.06705988]\n",
      " [0.05030318 0.08474547 0.2960779  0.5027143  0.06615911]\n",
      " [0.09284611 0.13587722 0.32487068 0.05110097 0.3953051 ]]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_categorical = []\n",
    "for prediction in preds:\n",
    "    preds_categorical.append(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    0: 'anger',\n",
    "    1: 'joy',\n",
    "    2: 'worry',\n",
    "    3: 'neutral',\n",
    "    4: 'sad'\n",
    "}\n",
    "pred_series = pd.Series(preds_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_predictions = pred_series.map(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry      794\n",
       "joy        749\n",
       "neutral    214\n",
       "sad        202\n",
       "anger       86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['emotion'] = review_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Nice budget hotel....room is clean and well ma...</td>\n",
       "      <td>nice budget hotelroom is clean and well mainta...</td>\n",
       "      <td>[nice, budget, hotelroom, is, clean, and, well...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>This hotel is well managed with great staff on...</td>\n",
       "      <td>this hotel is well managed with great staff on...</td>\n",
       "      <td>[this, hotel, is, well, managed, with, great, ...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>10 our of 10 lovely service, clean and homely....</td>\n",
       "      <td>our of lovely service clean and homely with lo...</td>\n",
       "      <td>[our, of, lovely, service, clean, and, homely,...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Very Dirty, carpet never been cleaned, Curry s...</td>\n",
       "      <td>very dirty carpet never been cleaned curry sta...</td>\n",
       "      <td>[very, dirty, carpet, never, been, cleaned, cu...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJiwVttYym2EcRUdFHMteOfCo</td>\n",
       "      <td>51.563524</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>Even 1 star is too much for this terrible hote...</td>\n",
       "      <td>even star is too much for this terrible hotel ...</td>\n",
       "      <td>[even, star, is, too, much, for, this, terribl...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id        lat       lng  \\\n",
       "0  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "1  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "2  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "3  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "4  ChIJiwVttYym2EcRUdFHMteOfCo  51.563524  0.070761   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Nice budget hotel....room is clean and well ma...   \n",
       "1  This hotel is well managed with great staff on...   \n",
       "2  10 our of 10 lovely service, clean and homely....   \n",
       "3  Very Dirty, carpet never been cleaned, Curry s...   \n",
       "4  Even 1 star is too much for this terrible hote...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  nice budget hotelroom is clean and well mainta...   \n",
       "1  this hotel is well managed with great staff on...   \n",
       "2  our of lovely service clean and homely with lo...   \n",
       "3  very dirty carpet never been cleaned curry sta...   \n",
       "4  even star is too much for this terrible hotel ...   \n",
       "\n",
       "                                      tokenized_text emotion  \n",
       "0  [nice, budget, hotelroom, is, clean, and, well...   worry  \n",
       "1  [this, hotel, is, well, managed, with, great, ...   worry  \n",
       "2  [our, of, lovely, service, clean, and, homely,...     joy  \n",
       "3  [very, dirty, carpet, never, been, cleaned, cu...     joy  \n",
       "4  [even, star, is, too, much, for, this, terribl...     joy  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.to_csv('../raw_data/review_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
