{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../raw_data/emotion_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotion                                               Text\n",
       "0     sad  Layin n bed with a headache  ughhhh...waitin o...\n",
       "1     sad                Funeral ceremony...gloomy friday...\n",
       "2     joy               wants to hang out with friends SOON!\n",
       "3   worry  Re-pinging @ghostridah14: why didn't you go to...\n",
       "4     sad  I should be sleep, but im not! thinking about ..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger      15872\n",
       "joy        14168\n",
       "worry      11786\n",
       "neutral    10212\n",
       "sad         9233\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61271, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Text']]\n",
    "y = data[['Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataframe):\n",
    "    \"\"\"\n",
    "    clean and preprocess data\n",
    "    \"\"\"\n",
    "    \n",
    "    data = dataframe.copy()\n",
    "\n",
    "    # Lowercase text\n",
    "    data['clean_text'] = data['Text'].apply(\n",
    "        lambda x: x.lower()\n",
    "        )\n",
    "\n",
    "    # Strip whitespace\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: x.strip()\n",
    "        )\n",
    "\n",
    "    # Remove numbers\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: ''.join(let for let in x if not let.isdigit())\n",
    "        )\n",
    "\n",
    "    # Remove punctuation\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: ''.join(let for let in x if not let in string.punctuation)\n",
    "        )\n",
    "\n",
    "    # Tokenization with nltk\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: word_tokenize(x)\n",
    "    )\n",
    "    \n",
    "    # Remove stopwords\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     data['clean_text'] = data['clean_text'].apply(\n",
    "#         lambda x: [word for word in x if word not in stop_words]\n",
    "#         )\n",
    "\n",
    "    # Lemmatizing with nltk\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data['clean_text'] = data['clean_text'].apply(\n",
    "        lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x)\n",
    "        )\n",
    "    \n",
    "    # Tokenizing text\n",
    "    data['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in data['clean_text']] \n",
    "\n",
    "    # Return data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_data(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>I'm sooo lost without my car  This is truly de...</td>\n",
       "      <td>im sooo lost without my car this is truly depr...</td>\n",
       "      <td>[im, sooo, lost, without, my, car, this, is, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30133</th>\n",
       "      <td>We plan to go to a forest in the suburb . The...</td>\n",
       "      <td>we plan to go to a forest in the suburb there ...</td>\n",
       "      <td>[we, plan, to, go, to, forest, in, the, suburb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37083</th>\n",
       "      <td>I see . Thanks for these tips . We really nee...</td>\n",
       "      <td>i see thanks for these tip we really need to b...</td>\n",
       "      <td>[see, thanks, for, these, tip, we, really, nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>Why am I limited to only being able to sync wi...</td>\n",
       "      <td>why am i limited to only being able to sync wi...</td>\n",
       "      <td>[why, am, limited, to, only, being, able, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55911</th>\n",
       "      <td>At the airport waiting</td>\n",
       "      <td>at the airport waiting</td>\n",
       "      <td>[at, the, airport, waiting]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "1689   I'm sooo lost without my car  This is truly de...   \n",
       "30133   We plan to go to a forest in the suburb . The...   \n",
       "37083   I see . Thanks for these tips . We really nee...   \n",
       "2460   Why am I limited to only being able to sync wi...   \n",
       "55911                             At the airport waiting   \n",
       "\n",
       "                                              clean_text  \\\n",
       "1689   im sooo lost without my car this is truly depr...   \n",
       "30133  we plan to go to a forest in the suburb there ...   \n",
       "37083  i see thanks for these tip we really need to b...   \n",
       "2460   why am i limited to only being able to sync wi...   \n",
       "55911                             at the airport waiting   \n",
       "\n",
       "                                          tokenized_text  \n",
       "1689   [im, sooo, lost, without, my, car, this, is, t...  \n",
       "30133  [we, plan, to, go, to, forest, in, the, suburb...  \n",
       "37083  [see, thanks, for, these, tip, we, really, nee...  \n",
       "2460   [why, am, limited, to, only, being, able, to, ...  \n",
       "55911                        [at, the, airport, waiting]  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
